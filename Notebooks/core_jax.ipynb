{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import jax"
      ],
      "metadata": {
        "id": "_41usXHkDLu9"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# JAX XLA Compiler\n",
        "XLA (Accelerated Linear Algebra) is a domain-specific compiler for linear algebra that plays a pivotal role in JAX's performance and flexibility. It enables Jax to generate optimized code for various hardware backends (CPUs, GPUs, TPUs) by transforming and compiling python code into efficient machine instructions.\n",
        "\n",
        "Jax uses XLA's Just In Time (JIT) compilation to transform your Python functions into optimized XLA computations at runtime."
      ],
      "metadata": {
        "id": "Gp5bstHk67Dl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Functional Programming & JAX\n",
        "\n",
        "The miracles of JAX only manifest themselves when code is written in a purely functional paradigm.\n",
        "\n",
        "*What are pure functions?*\n",
        "\n",
        "A function is said to be \"pure\" if its return value is solely determined by its input parameters and it has no side effects."
      ],
      "metadata": {
        "id": "XXAveT4S8JHf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Installation & Setup\n",
        "Follow the instruction here:\n",
        "[Installation](https://docs.jax.dev/en/latest/installation.html)"
      ],
      "metadata": {
        "id": "tQNCocHN9Q0H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# JAX Array programming"
      ],
      "metadata": {
        "id": "JXkUK6cP9n-s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import jax.numpy as jnp"
      ],
      "metadata": {
        "id": "26OxmKfN9QeU"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We create an array from a python list\n",
        "arr = jnp.array([1, 2, 3])\n",
        "arr"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SBJrmzL-xR-e",
        "outputId": "b9368b9f-45e1-4ead-dde5-b163fffb2c0c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Array([1, 2, 3], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'shape: {arr.shape}')\n",
        "print(f'dtype: {arr.dtype}')\n",
        "print(f'Device:{arr.devices()}')"
      ],
      "metadata": {
        "id": "KHbBMHdN_gWM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b3db0c3-d490-4424-fe95-1bc2166493b9"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape: (3,)\n",
            "dtype: int32\n",
            "Device:{CudaDevice(id=0)}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Immutability\n",
        "JAX arrays are immutable; We can't assign values by items, instead we should take a proper functional approach"
      ],
      "metadata": {
        "id": "f-Sun9vXBHKG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#arr[0] = 10   #This is going to throw an error"
      ],
      "metadata": {
        "id": "LaPjZgvV_52h"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Functional approach\n",
        "new_arr = arr.at[0].set(10)\n",
        "new_arr"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_NfLkxQZBFmU",
        "outputId": "e1a48721-c2a7-4555-b1b4-00d537db15eb"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Array([10,  2,  3], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Here's a cool demo of jax's workflow pattern\n",
        "\n",
        "def update_array(arr):\n",
        "  return arr.at[1:3].add(2).at[0].multiply(5)\n",
        "update_array(arr)\n",
        "# [1, 2, 3] --> [1*5, 2+2, 3+2] --> [5, 4, 5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uMlkiAMtBzVN",
        "outputId": "731f30f4-f22e-4397-b49d-3f3ffa55a015"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Array([5, 4, 5], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Device Placement"
      ],
      "metadata": {
        "id": "-lMVt7GkCqB6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from jax import devices\n",
        "print(devices()) #--> All available devices\n",
        "#For example I have a cpu and a gpu, and I want to place the computations on the gpu\n",
        "\n",
        "gpu_arr = jax.device_put(arr, devices('gpu')[0])\n",
        "#Output: [CudaDevice(id=0)]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t1-txE0pCYNv",
        "outputId": "5bc214f1-e4ca-4d21-acd3-c1ff0c2e0b9e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CudaDevice(id=0)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Distributed Arrays"
      ],
      "metadata": {
        "id": "50p5hwacENkY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To distribute arrays across available devices we use the **jax.sharding** module. Sharding is splitting an array into smaller chunks that are disributed across devices. At the moment, we are just going to use **Positional Sharding**  which distributes array chunks based on their position in the array."
      ],
      "metadata": {
        "id": "WOD85PXRFpAl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from jax.sharding import PositionalSharding\n",
        "\n",
        "sharding = PositionalSharding(jax.devices())\n",
        "distributed_arr = jax.device_put(jnp.arange(16))\n",
        "distributed_arr"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EijFyLLmCucJ",
        "outputId": "887ee2fb-c65a-49d4-cbbd-bc513f92abeb"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15],      dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Process management\n",
        "Let's suppose that we do not intent to immediately compute an array. We can use the *block_until_ready* module"
      ],
      "metadata": {
        "id": "Ns3GG1KMG0PH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "wait_arr = arr * 2 + 5\n",
        "\n",
        "block_process = wait_arr.block_until_ready()"
      ],
      "metadata": {
        "id": "G8eeGdVeGzyB"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## XLA Optimization\n",
        "\n",
        "we're going to compare between an optimized and unoptimized function."
      ],
      "metadata": {
        "id": "MMdKwTzSHXRu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def unoptimized_fn(x):\n",
        "  return x @ x.T + jnp.diag(jnp.ones(x.shape[0]))\n",
        "\n",
        "@jax.jit\n",
        "def optimized_fn(x):\n",
        "  return x @ x.T + jnp.diag(jnp.ones(x.shape[0]))"
      ],
      "metadata": {
        "id": "u_1iAcmdE9PF"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "large_arr = jax.random.normal(jax.random.PRNGKey(1), (5000, 5000))"
      ],
      "metadata": {
        "id": "FpUW6l9lH-E-"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Before going straight to the benchamrking code, we should warm-up the JIT compilation\n",
        "_ = optimized_fn(large_arr)"
      ],
      "metadata": {
        "id": "ydYpU3KbeefX"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "unop_start = time.time()\n",
        "unop_opt = unoptimized_fn(large_arr)\n",
        "unop_opt.block_until_ready()\n",
        "unop_end = time.time()\n",
        "\n",
        "print(f'Execution Time for the unoptimized function {unop_end - unop_start}s')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "itvqiY2_IJb4",
        "outputId": "4a35b9a2-46ed-4ed6-e00c-3f9642f1324d"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Execution Time for the unoptimized function 0.15828752517700195s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "op_start = time.time()\n",
        "op_opt =optimized_fn(large_arr)\n",
        "op_opt.block_until_ready()\n",
        "op_end = time.time()\n",
        "\n",
        "print(f'Execution Time for the optimized function {op_end - op_start}s')"
      ],
      "metadata": {
        "id": "-BBAhgd7I8nB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fcf06abb-8551-46cf-a0fc-a0eeb8f3210d"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Execution Time for the optimized function 0.08936452865600586s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Fqmgla4FJKAg"
      },
      "execution_count": 31,
      "outputs": []
    }
  ]
}