{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import jax\n",
        "import jax.numpy as jnp\n"
      ],
      "metadata": {
        "id": "ZE2aaXuuKoSx"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Performance Optimization\n",
        "## XLA Compiler Insights\n",
        "JAX relies on XLA (Accelerated Linear Algebra) to optimize and compile numerical computations.\n",
        "\n",
        "### Fusion Optimization\n",
        "Fusion is a key optimization technique where multiple operations are combined into a single operation to reduce memory transfers and improve performance"
      ],
      "metadata": {
        "id": "YeVW0SSFJJXL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Rf7szvGkJE4Q"
      },
      "outputs": [],
      "source": [
        "def without_fusion(x):\n",
        "  a = jnp.sin(x)\n",
        "  b = jnp.cos(x)\n",
        "  return a + b"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this example -without fusion- each operation would require multiple device memory transfers."
      ],
      "metadata": {
        "id": "zbOWJ9e3KVkd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@jax.jit\n",
        "def with_fusion(x):\n",
        "  a = jnp.sin(x)\n",
        "  b = jnp.cos(x)\n",
        "  return a + b"
      ],
      "metadata": {
        "id": "3axfr_j2KDQi"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this case, **jax.jit** triggers XLA compilation and enables more aggressive fusion, XLA combines these operations into one kernel which reduce memory transfers and improving performance.\n",
        "Note: Not all operations can be fused"
      ],
      "metadata": {
        "id": "7wa-FGPiKxWB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Memory layout management\n",
        "\n",
        "JAX manages memory with these features: immutability, just-in-Time compilation==> forces memory layouts to be determined ahead of time.\n",
        "JAX also manages device memory by handling transfers between CPU and accelerators (GPU/TPU) automatically. It also leverages XLA for memory optimizations."
      ],
      "metadata": {
        "id": "Oc3I90Oos5r3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### JAX Sharding: Distributed Array Storage\n",
        "\n",
        "Sharding in JAX refers to splitting arrays across multiple devices (Like GPUs, or TPUs) to enable parallel computation."
      ],
      "metadata": {
        "id": "YOcgYUSwubKy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This code my throw an error it depends on your system, the configuration here is for 2*T4 GPU\n",
        "import jax\n",
        "import numpy as np\n",
        "import jax.numpy as jnp\n",
        "from jax.sharding import Mesh, PartitionSpec as P\n",
        "\n",
        "# Create a 2D mesh of devices\n",
        "devices = jax.devices()\n",
        "mesh = Mesh(np.array(devices).reshape(1,2), ('batch', 'model'))\n",
        "print(mesh)\n",
        "# Define how to partition the array\n",
        "spec = P('batch', 'model')  # Shard along both dimensions\n",
        "\n",
        "# Create and shard an array\n",
        "x = jnp.ones((16, 8))\n",
        "x_sharded = jax.device_put(x, jax.sharding.NamedSharding(mesh, spec))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "Ow6-1Zcluizz",
        "outputId": "5306bdaa-5377-4fb3-e0d8-11b2e4702d2b"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "cannot reshape array of size 1 into shape (1,2)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-4a17d5fbd53a>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Create a 2D mesh of devices\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mdevices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mmesh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMesh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'batch'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'model'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmesh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Define how to partition the array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 1 into shape (1,2)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QEcWGf3p0mhK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}